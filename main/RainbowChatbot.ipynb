{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28daeb3e-23d9-4bef-b72b-d17631f61e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Project: Building an Interactive AI Rainbow on a Budget Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d8b01-d2eb-4dbb-a127-e48135ff3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries, API and set filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6cc0a38-c641-47f1-b66e-60deba1d8fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\tommy\\anaconda3\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Requirement already satisfied: llama-index==0.8.64 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (0.8.64)\n",
      "Requirement already satisfied: pypdf in c:\\users\\tommy\\anaconda3\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\tommy\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: ragas in c:\\users\\tommy\\anaconda3\\lib\\site-packages (0.1.13)\n",
      "Requirement already satisfied: openai in c:\\users\\tommy\\anaconda3\\lib\\site-packages (1.40.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index==0.8.64) (2.0.25)\n",
      "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (0.5.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (1.2.14)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (2023.10.0)\n",
      "Requirement already satisfied: langchain>=0.0.303 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (0.2.12)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (1.6.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (2.1.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from llama-index==0.8.64) (1.26.19)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.44.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.24.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from ragas) (2.20.0)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from ragas) (0.2.28)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from ragas) (0.2.11)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from ragas) (0.1.20)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from ragas) (0.3.4)\n",
      "Requirement already satisfied: appdirs in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->llama-index==0.8.64) (3.21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index==0.8.64) (1.14.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from langchain>=0.0.303->llama-index==0.8.64) (3.9.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from langchain>=0.0.303->llama-index==0.8.64) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from langchain>=0.0.303->llama-index==0.8.64) (0.1.96)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: click in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.8.64) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.8.64) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.8.64) (2023.10.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index==0.8.64) (3.0.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index==0.8.64) (1.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from datasets->ragas) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from datasets->ragas) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from datasets->ragas) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from pandas->llama-index==0.8.64) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from pandas->llama-index==0.8.64) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from pandas->llama-index==0.8.64) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index==0.8.64) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index==0.8.64) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index==0.8.64) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index==0.8.64) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index==0.8.64) (1.9.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain>=0.0.303->llama-index==0.8.64) (3.10.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index==0.8.64) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tommy\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install llama_index==0.8.64\n",
    "#!pip install openai==1.19.0\n",
    "!pip install spacy\n",
    "!pip install llama-index==0.8.64 pypdf sentence-transformers ragas openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3dd0392-845d-477c-809a-4efa6d589856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index import Document, GPTVectorStoreIndex, ServiceContext, VectorStoreIndex\n",
    "from llama_index.readers import BeautifulSoupWebReader, SimpleDirectoryReader\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "\n",
    "import openai\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_index import download_loader\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "from llama_index.callbacks import OpenAIFineTuningHandler\n",
    "from llama_index.callbacks import CallbackManager\n",
    "\n",
    "import random\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4f89dd-657d-42f7-b349-05fa8faec73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filepath to my data directory \n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, \"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321db7ab-fb42-4877-beea-f6985e747fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08573364-79fc-46e7-b25b-6871c5246f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from llama_index import download_loader\n",
    "\n",
    "PagedCSVReader = download_loader(\"PagedCSVReader\")\n",
    "\n",
    "loader = PagedCSVReader(encoding=\"utf-8\")\n",
    "docs = loader.load_data(file=Path('./data/products.csv')) \n",
    "\n",
    "#read and load the csv file into the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807e6d18-d112-4798-b451-3f84f9c553ee",
   "metadata": {},
   "source": [
    "## Build Index\n",
    "\n",
    "#With all the data loaded, we can construct the index for the chatbot. There are 4 types of indexing: Summary index, VectorStore Index, Tree Index and Keyword Table Index. Here we are using VectorStore Index, which is also one of the most common types of indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529d3973-131a-4c8b-a04c-e22b5347210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0) # degree of randomness from 0 to 1. \n",
    ")\n",
    "\n",
    "index = GPTVectorStoreIndex.from_documents(documents=docs, service_context=service_context)\n",
    "\n",
    "\n",
    "#method is used to create an index from a set of documents (docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b79d3f-cb57-4e7f-a9bb-390311ccad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the output as a vector store so that we can refer to this \n",
    "# instead of running the embedding model above again\n",
    "\n",
    "index.storage_context.persist(persist_dir=\"./data/index.vecstore\")  \n",
    "\n",
    "#the data is stored in that location, making it easier to load the index from storage later on without having to re-index the documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb5dcaa0-f047-496e-8c94-00d90d531024",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a0391c3-2cf3-4695-bf30-3a5d06af30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the documents\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(docs)\n",
    "\n",
    "gpt_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f17d6c20-5775-4a4a-b99a-9330fc561f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen_query=(\n",
    "    \"Craft a series of questions that customers might ask about what fruits and vegetables to add to their diet to achieve the optimal nutrition. The fruits and vegetables in their cart should include at least 1 item from the Red column, Yellow & Orange column, White, Tan & Brown column, Green column and Blue & Purple column of the same row of the data file. Check if the user input has at least one item from each of these columns and then provide the full row of values that are closest to the user input which must include the full recipe in the corresponding Recipes column. You must only use the data from the dataset provided\"\n",
    ")\n",
    "# find out more about question generation from \n",
    "# https://gpt-index.readthedocs.io/en/latest/examples/evaluation/QuestionGeneration.html\n",
    "\n",
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    docs[:24],\n",
    "    question_gen_query=question_gen_query,\n",
    "    service_context=gpt_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3559057b-1a4f-4173-83c6-6c60b8866b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "#The code snippet import nest_asyncio; nest_asyncio.apply() is used to enable nested event loops in asyncio, which is the default behavior in Python's asyncio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd742a84-3afe-4d44-b7bc-2aaaf2e70d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  25  questions\n"
     ]
    }
   ],
   "source": [
    "questions = dataset_generator.generate_questions_from_nodes(num=25)   \n",
    "print(\"Generated \", len(questions), \" questions\")\n",
    "#generates a list of questions based on the documents. 25 questions generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f1e10e2-c67e-470b-a4a0-605c7962410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What fruits and vegetables should I add to my diet to achieve optimal nutrition?\n",
      "Can you suggest a combination of fruits and vegetables from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns for a balanced diet?\n",
      "How can I incorporate items from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns into my meals for optimal nutrition?\n",
      "What recipe can I make using ingredients from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns for a nutritious meal?\n",
      "Are there any specific fruits and vegetables I should focus on from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns for a well-rounded diet?\n",
      "Can you provide a list of fruits and vegetables from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns that are recommended for optimal nutrition?\n",
      "How can I ensure I am getting a variety of nutrients by including items from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns in my diet?\n",
      "What are some creative ways to incorporate fruits and vegetables from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns into my meals for a balanced diet?\n",
      "Is there a specific recipe that includes ingredients from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns that you recommend for a nutritious meal?\n",
      "Can you suggest a meal plan that includes items from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns for optimal nutrition?\n",
      "What fruits and vegetables should I add to my diet to achieve optimal nutrition?\n",
      "Can you recommend a balanced combination of fruits and vegetables for a nutritious diet?\n",
      "What are some red fruits and vegetables that I should include in my meals?\n",
      "Which yellow or orange fruits would be beneficial for my health?\n",
      "What white, tan, or brown fruits and vegetables are essential for a well-rounded diet?\n",
      "Are there any green vegetables that I should prioritize in my meals?\n",
      "What are the benefits of including blue or purple fruits and vegetables in my diet?\n",
      "Can you suggest a recipe that incorporates a variety of colorful fruits and vegetables for optimal nutrition?\n",
      "How can I ensure I am getting a diverse range of nutrients from my fruits and vegetables?\n",
      "What are some creative ways to incorporate a variety of colorful produce into my meals?\n",
      "What fruits and vegetables should I add to my diet to achieve optimal nutrition?\n",
      "Can you recommend a combination of fruits and vegetables from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns for a balanced diet?\n",
      "How can I incorporate items from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns into my meals for optimal nutrition?\n",
      "What recipe can I make using ingredients from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns for a nutritious meal?\n",
      "Are there any specific fruits and vegetables I should focus on to ensure I am getting a variety of nutrients in my diet?\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_questions.txt\", \"w\") as f:\n",
    "    for question in questions:\n",
    "        f.write(question + \"\\n\")\n",
    "        print(question)\n",
    "        \n",
    "# writes a list of questions to a file named train_questions.txt and prints each question to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38cf34-9cb3-4f32-81f5-f5c616351b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'train_questions.txt'\n",
    "output_file_path = 'modified_train_questions.txt'\n",
    "\n",
    "def postprocess(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        modified_lines = [line.replace(\"Question:\", \"\").strip() for line in file]\n",
    "\n",
    "    with open(output_file_path, 'w') as new_file:\n",
    "        for line in modified_lines:\n",
    "            new_file.write(line + '\\n')\n",
    "            \n",
    "#modifies the content by removing a specific string (\"Question:\") from each line, and writes the modified lines to a new output file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e8312b71-3b87-4e83-b14f-b3e744b29d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Eval Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "162834b9-55d1-4c06-a634-c8d6e6e57c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    docs[\n",
    "        25:49\n",
    "    ],\n",
    "    question_gen_query=question_gen_query,\n",
    "    service_context=gpt_context,\n",
    ")\n",
    "\n",
    "# generate datasets (potentially question-answer pairs) from a specified subset of documents. The subset is defined by slicing the docs list from index 30 to 54 (Python slicing is exclusive of the end index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5666715e-c9eb-4558-a246-b44fd3fb8a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  25  questions\n"
     ]
    }
   ],
   "source": [
    "questions = dataset_generator.generate_questions_from_nodes(num=25)\n",
    "print(\"Generated \", len(questions), \" questions\")\n",
    "#generates a list of questions based on the documents. 25 question generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6b07a41-3372-40e9-83cd-9310ab06709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"eval_questions.txt\", \"w\") as f:\n",
    "    for question in questions:\n",
    "        f.write(question + \"\\n\")\n",
    "#writes a list of questions to a file named eval_questions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6502c846-8502-47ab-8a2c-7472cb01607d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'postprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m input_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_questions.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified_eval_questions.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m postprocess(input_file_path, output_file_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'postprocess' is not defined"
     ]
    }
   ],
   "source": [
    "input_file_path = 'eval_questions.txt'\n",
    "output_file_path = 'modified_eval_questions.txt'\n",
    "\n",
    "postprocess(input_file_path, output_file_path)\n",
    "\n",
    "#modify the content of a file named eval_questions.txt and write the modified content to a new file named modified_eval_questions.txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0fa7b62-2d3a-4ddd-a55e-6da64509084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of documents:\", len(docs))\n",
    "#prints the total number of documents in the docs list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cad330-1f7d-4e69-9649-23cabe67a666",
   "metadata": {},
   "source": [
    "## Initial Evaluation\n",
    "\n",
    "For this evaluation with GPT-3.5 Query Engine, we will be using the [`ragas` evaluation library](https://github.com/explodinggradients/ragas).\n",
    "\n",
    "For this notebook, we will be using the following two metrics:\n",
    "\n",
    "- `answer_relevancy` - This measures how relevant is the generated answer to the prompt. If the generated answer is incomplete or contains redundant\n",
    "- information the score will be low. This is quantified by working out the chance of an LLM generating the given question using the generated answer. Values range (0,1), higher the better.  \n",
    "- `faithfulness` - This measures the factual consistency of the generated answer against the given context. This is done using a multi step paradigm that includes creation of statements from the generated answer followed by verifying each of these statements against the context. The answer is scaled to (0,1) range. Higher the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eb6c5d2-b02a-4215-a65b-1b81249f25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"eval_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())\n",
    "#reads questions from a file named modified_eval_questions.txt and stores them in a list named questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e009906e-a286-4bf1-8fe6-d94ab2949dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "# limit the context window to 2048 tokens so that refine is used\n",
    "gpt_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"ft:gpt-3.5-turbo-1106:personal:capstone-exp-3:9vgnLOrh\", temperature=0), context_window=2048\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs, service_context=gpt_context)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "#GPT-3.5-turbo model to understand the semantic content of documents and then uses this understanding to find documents that are semantically similar to a given query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bfcc2ed-21cc-47cf-9d83-40eb4ab6a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "answers = []\n",
    "\n",
    "\n",
    "for question in questions:\n",
    "    response = query_engine.query(question)\n",
    "    contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "    answers.append(str(response))\n",
    "\n",
    "#store the contexts and answers of the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfe9ca7c-7b9f-4271-8d6a-b2812a35b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What fruits and vegetables should I add to my diet to achieve optimal nutrition?',\n",
       " 'Can you suggest a combination of fruits and vegetables from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns for a balanced diet?',\n",
       " 'How can I incorporate strawberries, yellow watermelon, garlic, celery, and Concord grapes into my meals for optimal nutrition?',\n",
       " 'What recipe can I make using strawberries, yellow watermelon, garlic, celery, and Concord grapes for a nutritious meal?',\n",
       " 'Are there any specific dishes or recipes that include a variety of fruits and vegetables like strawberries, yellow watermelon, garlic, celery, and Concord grapes for a well-rounded diet?',\n",
       " 'Can you provide a meal plan that includes strawberries, yellow watermelon, garlic, celery, and Concord grapes for a healthy lifestyle?',\n",
       " 'What are the health benefits of consuming a combination of strawberries, yellow watermelon, garlic, celery, and Concord grapes regularly?',\n",
       " 'How can I ensure I am getting all the necessary nutrients by including strawberries, yellow watermelon, garlic, celery, and Concord grapes in my diet?',\n",
       " 'Are there any specific cooking methods or recipes that highlight the flavors and nutrients of strawberries, yellow watermelon, garlic, celery, and Concord grapes together?',\n",
       " 'Can you recommend a balanced meal using strawberries, yellow watermelon, garlic, celery, and Concord grapes that is easy to prepare and delicious to eat?',\n",
       " 'What fruits and vegetables should I add to my diet to achieve optimal nutrition?',\n",
       " 'Can you recommend a combination of fruits and vegetables from the Red, Yellow & Orange, White, Tan & Brown, Green, and Blue & Purple columns for a balanced diet?',\n",
       " 'How can I incorporate radishes, passionfruit yellow, mushrooms, sugar snap peas, and black beans into my meals for optimal nutrition?',\n",
       " 'What recipe can I make using Grozer Daikon White Radish, YayaPapaya Passionfruit Yellow, Hokto Mushroom - Bunashimeji, Orgo Fresh Sweet Sugar Snap Peas, and Dr Gram Organic Black Bean?',\n",
       " 'Are there any specific recipes that include a variety of fruits and vegetables from different color categories for a well-rounded meal?',\n",
       " 'Can you suggest a meal plan that includes radishes, passionfruit yellow, mushrooms, sugar snap peas, and black beans for a balanced diet?',\n",
       " 'How can I ensure I am getting a diverse range of nutrients by incorporating red, yellow, white, green, and blue fruits and vegetables into my meals?',\n",
       " 'What are some creative ways to combine different colored fruits and vegetables like radishes, passionfruit yellow, mushrooms, sugar snap peas, and black beans in my diet?',\n",
       " 'Are there any specific health benefits associated with consuming a variety of fruits and vegetables from different color categories?',\n",
       " 'Can you provide a recipe that includes all the recommended fruits and vegetables for optimal nutrition, such as Grozer Daikon White Radish, YayaPapaya Passionfruit Yellow, Hokto Mushroom - Bunashimeji, Orgo Fresh Sweet Sugar Snap Peas, and Dr Gram Organic Black Bean?',\n",
       " 'What fruits and vegetables should I add to my diet to achieve optimal nutrition?',\n",
       " 'Can you provide a list of fruits and vegetables from the Red column for optimal nutrition?',\n",
       " 'What are some examples of Yellow & Orange fruits and vegetables for a balanced diet?',\n",
       " 'Which White, Tan & Brown fruits and vegetables should I include in my meals?',\n",
       " 'What are some Green fruits and vegetables that are essential for optimal nutrition?']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8265ca9-66a7-4d52-8f18-60b27d8a7865",
   "metadata": {},
   "source": [
    "## Create Fine Tuned Engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cc7475c-f470-4550-9d4c-c8451d241611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.callbacks import OpenAIFineTuningHandler\n",
    "from llama_index.callbacks import CallbackManager\n",
    "\n",
    "finetuning_handler = OpenAIFineTuningHandler()\n",
    "callback_manager = CallbackManager([finetuning_handler])\n",
    "\n",
    "gpt_35_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"ft:gpt-3.5-turbo-1106:personal:capstone-exp-3:9vgnLOrh\", temperature=0),\n",
    "    context_window=2048,  # limit the context window artifically to test refine process\n",
    "    callback_manager=callback_manager,\n",
    ")\n",
    "#GPT-3.5-turbo model to understand the semantic content of documents and then uses this understanding to find documents that are semantically similar to a given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e604e4c-1dbc-477c-bda7-e0cbab8f0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs, service_context=gpt_35_context)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)\n",
    "#create a VectorStoreIndex from a collection of documents (docs) using the LlamaIndex library, and then convert this index into a query engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51918115-4841-4a56-8740-df101bee0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"train_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())\n",
    "#reads questions from a file named modified_train_questions.txt and stores them in a list named questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72e22577-4345-4c1e-995a-86a26e10d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    response = query_engine.query(question)\n",
    "\n",
    "# loop that iterates over a list of questions, querying a query_engine for each question and storing the response in a variable named respons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "305f9e29-3f12-4fd3-b614-8885570c94c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 25 examples to finetune.jsonl\n"
     ]
    }
   ],
   "source": [
    "finetuning_handler.save_finetuning_events(\"finetune.jsonl\")\n",
    "#save fine-tuning events to a JSONL file called finetune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a62ab5-e7d1-4c7e-90ff-823392d93b36",
   "metadata": {},
   "source": [
    "## Evaluating Fine Tuned Engine\n",
    "\n",
    "After some time, your model will be done training!\n",
    "\n",
    "The next step is running our fine-tuned model on our eval dataset again to measure any performance increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1885fbb3-6c4c-42bd-a667-843ed004bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"eval_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())\n",
    "#reads a text file named eval_questions.txt line by line, strips any leading or trailing whitespace (including newlines) from each line, and appends each line to a list named questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d8474a4-3eda-4acd-9c9d-1d85249812c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "ft_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"ft:gpt-3.5-turbo-1106:personal:capstone-exp-3:9vgnLOrh\",temperature=0, openai_api_key=openai.api_key), context_window=2048\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(docs, service_context=ft_context)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "#query engine using the VectorStoreIndex from the llama_index library, specifically tailored for fine-tuning a language model (LLM) like GPT-3.5 Turbo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b482fd2d-c54f-4610-aed9-064b36c4ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    response = query_engine.query(question)\n",
    "    contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "    answers.append(str(response))\n",
    "#query engine to process a list of questions and collect both the contexts (source nodes) and answers from the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e50765a6-10cd-4da2-ae82-a04d171b9015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d089082bd2b44fc0922cda767dd7ce79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9128, 'faithfulness': 0.5017}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "result = evaluate(ds, [answer_relevancy, faithfulness])\n",
    "print(result)\n",
    "#evaluate result on answer_relevancy & faithfulness using ragas. Ragas score  = (answer_relevancy + faithfulness) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6b88e-2fc0-4cae-af4a-e80effdb83b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a720c37-c90c-4a8b-8c5b-21f5ed5d3358",
   "metadata": {},
   "source": [
    "Second evaluation - Baseline Model - GPT 4.0 (non-finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cffcbb4c-60d0-4fc2-a17b-a243806199d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"eval_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())\n",
    "#reads questions from a file named modified_eval_questions.txt and stores them in a list named questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2928ac71-77f9-457d-ac27-8a1b20744419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "ft_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-4\",temperature=0, openai_api_key=openai.api_key), context_window=2048\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(docs, service_context=ft_context)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "#query engine using the VectorStoreIndex from the llama_index library, specifically tailored for fine-tuning a language model (LLM) like GPT-3.5 Turbo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c42fed4a-6043-454e-8ecf-994b1f766603",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    response = query_engine.query(question)\n",
    "    contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "    answers.append(str(response))\n",
    "#query engine to process a list of questions and collect both the contexts (source nodes) and answers from the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6918b406-2af1-4c9e-b12e-b46c3060e3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa8a62a902f45428bfaf3bfac686b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.6685, 'faithfulness': 0.7370}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "result = evaluate(ds, [answer_relevancy, faithfulness])\n",
    "print(result)\n",
    "#evaluate result on answer_relevancy & faithfulness using ragas. Ragas score  = (answer_relevancy + faithfulness) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70923765-6b42-456e-a8df-13252f6b36e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfb4ec-57eb-4c13-bc62-ac0f7c574112",
   "metadata": {},
   "outputs": [],
   "source": [
    "Third evaluation - Baseline Model - GPT 4o mini (non-finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09c1a506-a51f-4c66-a613-54048395cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"eval_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())\n",
    "#reads questions from a file named modified_eval_questions.txt and stores them in a list named questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7590c037-6a42-4304-a208-6f31779a29a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown model 'gpt-4o-mini-2024-07-18'. Please provide a valid OpenAI model name in: gpt-4, gpt-4-32k, gpt-4-1106-preview, gpt-4-vision-preview, gpt-4-0613, gpt-4-32k-0613, gpt-4-0314, gpt-4-32k-0314, gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-3.5-turbo-1106, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, gpt-3.5-turbo-0301, text-davinci-003, text-davinci-002, gpt-3.5-turbo-instruct, text-ada-001, text-babbage-001, text-curie-001, ada, babbage, curie, davinci, gpt-35-turbo-16k, gpt-35-turbo",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex\n\u001b[1;32m----> 3\u001b[0m ft_context \u001b[38;5;241m=\u001b[39m ServiceContext\u001b[38;5;241m.\u001b[39mfrom_defaults(\n\u001b[0;32m      4\u001b[0m     llm\u001b[38;5;241m=\u001b[39mOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft:gpt-4o-mini-2024-07-18:personal::9yERXbv7\u001b[39m\u001b[38;5;124m\"\u001b[39m,temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, openai_api_key\u001b[38;5;241m=\u001b[39mopenai\u001b[38;5;241m.\u001b[39mapi_key), context_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(docs, service_context\u001b[38;5;241m=\u001b[39mft_context)\n\u001b[0;32m      8\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_query_engine(similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\indices\\service_context.py:172\u001b[0m, in \u001b[0;36mServiceContext.from_defaults\u001b[1;34m(cls, llm_predictor, llm, prompt_helper, embed_model, node_parser, llama_logger, callback_manager, system_prompt, query_wrapper_prompt, pydantic_program_mode, chunk_size, chunk_overlap, context_window, num_output, chunk_size_limit)\u001b[0m\n\u001b[0;32m    168\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m resolve_embed_model(embed_model)\n\u001b[0;32m    169\u001b[0m embed_model\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m callback_manager\n\u001b[0;32m    171\u001b[0m prompt_helper \u001b[38;5;241m=\u001b[39m prompt_helper \u001b[38;5;129;01mor\u001b[39;00m _get_default_prompt_helper(\n\u001b[1;32m--> 172\u001b[0m     llm_metadata\u001b[38;5;241m=\u001b[39mllm_predictor\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[0;32m    173\u001b[0m     context_window\u001b[38;5;241m=\u001b[39mcontext_window,\n\u001b[0;32m    174\u001b[0m     num_output\u001b[38;5;241m=\u001b[39mnum_output,\n\u001b[0;32m    175\u001b[0m )\n\u001b[0;32m    177\u001b[0m node_parser \u001b[38;5;241m=\u001b[39m node_parser \u001b[38;5;129;01mor\u001b[39;00m _get_default_node_parser(\n\u001b[0;32m    178\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[0;32m    179\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39mchunk_overlap,\n\u001b[0;32m    180\u001b[0m     callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[0;32m    181\u001b[0m )\n\u001b[0;32m    183\u001b[0m llama_logger \u001b[38;5;241m=\u001b[39m llama_logger \u001b[38;5;129;01mor\u001b[39;00m LlamaLogger()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\llm_predictor\\base.py:120\u001b[0m, in \u001b[0;36mLLMPredictor.metadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetadata\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMMetadata:\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get LLM metadata.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mmetadata\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\llms\\openai.py:142\u001b[0m, in \u001b[0;36mOpenAI.metadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetadata\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMMetadata:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LLMMetadata(\n\u001b[1;32m--> 142\u001b[0m         context_window\u001b[38;5;241m=\u001b[39mopenai_modelname_to_contextsize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_name()),\n\u001b[0;32m    143\u001b[0m         num_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    144\u001b[0m         is_chat_model\u001b[38;5;241m=\u001b[39mis_chat_model(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_name()),\n\u001b[0;32m    145\u001b[0m         is_function_calling_model\u001b[38;5;241m=\u001b[39mis_function_calling_model(\n\u001b[0;32m    146\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_name()\n\u001b[0;32m    147\u001b[0m         ),\n\u001b[0;32m    148\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    149\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\llms\\openai_utils.py:185\u001b[0m, in \u001b[0;36mopenai_modelname_to_contextsize\u001b[1;34m(modelname)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has been discontinued. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease choose another model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modelname \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ALL_AVAILABLE_MODELS:\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m. Please provide a valid OpenAI model name in:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ALL_AVAILABLE_MODELS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ALL_AVAILABLE_MODELS[modelname]\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown model 'gpt-4o-mini-2024-07-18'. Please provide a valid OpenAI model name in: gpt-4, gpt-4-32k, gpt-4-1106-preview, gpt-4-vision-preview, gpt-4-0613, gpt-4-32k-0613, gpt-4-0314, gpt-4-32k-0314, gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-3.5-turbo-1106, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, gpt-3.5-turbo-0301, text-davinci-003, text-davinci-002, gpt-3.5-turbo-instruct, text-ada-001, text-babbage-001, text-curie-001, ada, babbage, curie, davinci, gpt-35-turbo-16k, gpt-35-turbo"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "ft_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"ft:gpt-4o-mini-2024-07-18:personal::9yERXbv7\",temperature=0, openai_api_key=openai.api_key), context_window=2048\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(docs, service_context=ft_context)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "#query engine using the VectorStoreIndex from the llama_index library, specifically tailored for fine-tuning a language model (LLM) like GPT-3.5 Turbo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bcedb-cb58-4627-9f6a-a836935e1ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    response = query_engine.query(question)\n",
    "    contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "    answers.append(str(response))\n",
    "#query engine to process a list of questions and collect both the contexts (source nodes) and answers from the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa36bd-c7d2-4bd8-a009-62206a20b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "result = evaluate(ds, [answer_relevancy, faithfulness])\n",
    "print(result)\n",
    "#evaluate result on answer_relevancy & faithfulness using ragas. Ragas score  = (answer_relevancy + faithfulness) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f1912-fdea-45b8-bc96-849eb5553c45",
   "metadata": {},
   "source": [
    "## {Tentative] Baseline Model - GPT 3.5 Turbo (Non-finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82ea89ce-b79c-4fc9-9faa-3869098904c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a18b52aa1444308b876cbc0f7cf1500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9391, 'faithfulness': 0.4543}\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "result = evaluate(ds,[answer_relevancy, faithfulness])\n",
    "print(result)\n",
    "\n",
    "# Evaluate the answer_relevancy & faithfulness using ragas. Ragas score  = (answer_relevancy + faithfulness) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f8206-f974-4d80-912d-300c36016bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0fc96-d925-47dd-929b-a4cee6b30c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
